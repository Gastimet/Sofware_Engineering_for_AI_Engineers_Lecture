services:
  mlflow:
    # FIX: Use the same build context as trainer.
    # This uses the image we just built, which already has mlflow installed.
    # No more 'pip install' at runtime means no timeouts!
    build:
      context: ..
      dockerfile: Autogluon_multiple_regression_models/Dockerfile
    container_name: mlflow
    working_dir: /app
    # Command is now just starting the server (dependencies are already in the image)
    command: sh -c "mlflow server --backend-store-uri sqlite:////mlflow/mlflow.db --default-artifact-root file:/mlruns --host 0.0.0.0 --port 5000"
    ports:
      - "5000:5000"
    volumes:
      - mlruns_data:/mlruns
      - mlflow_data:/mlflow
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request,sys; urllib.request.urlopen('http://localhost:5000').read(); sys.exit(0)"]
      interval: 5s
      timeout: 5s
      retries: 20
      start_period: 10s

  trainer:
    build:
      context: ..
      dockerfile: Autogluon_multiple_regression_models/Dockerfile
    container_name: trainer
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      PYTHONUNBUFFERED: "1"
    volumes:
      - mlruns_data:/mlruns
    working_dir: /workspace
    depends_on:
      mlflow:
        condition: service_healthy
    command: sh -c "cd /workspace/Autogluon_multiple_regression_models && python -m src.pipeline.train --task churn --data-csv-a /workspace/Autogluon_multiple_regression_models/example_data/source_a.csv --data-csv-b /workspace/Autogluon_multiple_regression_models/example_data/source_b.csv --join-keys customer_id --target churned --promote"

volumes:
  mlflow_data:
  mlruns_data: